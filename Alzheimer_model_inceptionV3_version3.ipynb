{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LikaOkudzhava/BrainyScan/blob/InceptionV3/Alzheimer_model_inceptionV3_version3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "saHrK7K9Q-Bt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d847fe2-42e6-4642-bda7-f3435e559e42"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oRfYA4mlQzww"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "import keras\n",
        "from keras.callbacks import EarlyStopping,ModelCheckpoint\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from imblearn.over_sampling import SMOTE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uB1a8LF8RUgi"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "import zipfile\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "gdrive = '/content/drive'\n",
        "\n",
        "gdisk = os.path.join(gdrive, 'MyDrive')\n",
        "\n",
        "filename = 'smallpreprocessed'\n",
        "\n",
        "archive_path = os.path.join(gdisk, filename)\n",
        "\n",
        "with zipfile.ZipFile('/content/drive/MyDrive/AI/smallpreprocessed.zip', 'r') as zip_ref:\n",
        "\n",
        " zip_ref.extractall(f'{filename}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OaVcj5usQzw8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c71b0c5-41ad-4850-e871-cb5972a9fbcd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 12000 files belonging to 4 classes.\n",
            "Found 2000 files belonging to 4 classes.\n",
            "Found 2000 files belonging to 4 classes.\n"
          ]
        }
      ],
      "source": [
        "dataset_dir = '/content/smallpreprocessed/data/SmallPreprocessed'\n",
        "image_height = 299\n",
        "image_width = 299\n",
        "batch_size = 16\n",
        "\n",
        "\n",
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    os.path.join(dataset_dir, 'train'),\n",
        "    labels = 'inferred',\n",
        "    label_mode = 'categorical',\n",
        "    image_size = (image_height, image_width),\n",
        "    batch_size = batch_size,\n",
        "    shuffle = True\n",
        ")\n",
        "\n",
        "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    os.path.join(dataset_dir, 'test'),\n",
        "    labels = 'inferred',\n",
        "    label_mode = 'categorical',\n",
        "    image_size = (image_height, image_width),\n",
        "    batch_size = batch_size,\n",
        "    shuffle = False\n",
        ")\n",
        "\n",
        "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    os.path.join(dataset_dir, 'val'),\n",
        "    labels = 'inferred',\n",
        "    label_mode = 'categorical',\n",
        "    image_size = (image_height, image_width),\n",
        "    batch_size = batch_size,\n",
        "    shuffle = True\n",
        ")\n",
        "\n",
        "for ds in [train_ds, test_ds, val_ds]:\n",
        "    ds.cache()\n",
        "    ds.prefetch(buffer_size=tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SOACOTC2z_2g"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "\n",
        "# Load InceptionV3 with all layers frozen\n",
        "model = keras.applications.InceptionV3(\n",
        "    include_top=False,\n",
        "    weights=\"imagenet\",\n",
        "    input_shape=(299, 299, 3)\n",
        ")\n",
        "\n",
        "# Freeze all layers\n",
        "for layer in model.layers:\n",
        "    layer.trainable = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7-E44jt4QzxA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        },
        "outputId": "51d8a158-1a36-470b-d01d-8430387441f1"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_5\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_5\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_26 (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m299\u001b[0m, \u001b[38;5;34m299\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ inception_v3 (\u001b[38;5;33mFunctional\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │    \u001b[38;5;34m21,802,784\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1332        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │         \u001b[38;5;34m8,192\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_15 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │     \u001b[38;5;34m4,196,352\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1333        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │         \u001b[38;5;34m8,192\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_16 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │     \u001b[38;5;34m2,098,176\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1334        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │         \u001b[38;5;34m4,096\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_17 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │         \u001b[38;5;34m4,100\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">299</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">299</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ inception_v3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │    <span style=\"color: #00af00; text-decoration-color: #00af00\">21,802,784</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1332        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,192</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">4,196,352</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1333        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,192</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,098,176</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1334        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,100</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m28,121,892\u001b[0m (107.28 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">28,121,892</span> (107.28 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m6,308,868\u001b[0m (24.07 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,308,868</span> (24.07 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m21,813,024\u001b[0m (83.21 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">21,813,024</span> (83.21 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "\n",
        "# Image dimensions\n",
        "image_height = 299\n",
        "image_width = 299\n",
        "input_shape = (image_height, image_width, 3)\n",
        "\n",
        "# Input layer\n",
        "inputs = keras.Input(shape=input_shape)\n",
        "\n",
        "# Skip augmentation — direct input\n",
        "x = inputs\n",
        "\n",
        "# Load InceptionV3 base model with pretrained weights\n",
        "base_model = tf.keras.applications.InceptionV3(\n",
        "    include_top=False,\n",
        "    weights='imagenet',\n",
        "    input_shape=input_shape,\n",
        "    pooling='avg'  # Outputs a global average pooled vector\n",
        ")\n",
        "base_model.trainable = False  # Freeze pretrained weights\n",
        "\n",
        "# Pass input through base model\n",
        "x = base_model(x)\n",
        "\n",
        "# Custom classification head\n",
        "x = keras.layers.BatchNormalization()(x)\n",
        "x = keras.layers.Dense(2048, activation='relu')(x)\n",
        "x = keras.layers.BatchNormalization()(x)\n",
        "x = keras.layers.Dense(1024, activation='relu')(x)\n",
        "x = keras.layers.BatchNormalization()(x)\n",
        "outputs = keras.layers.Dense(4, activation='softmax')(x)  # 4 classes\n",
        "\n",
        "# Combine into a full model\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "# Show model summary\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model.fit(train_ds, validation_data=val_ds, epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UmEdo0pWF74H",
        "outputId": "7afd96a5-b927-4282-e813-490e4ce10bd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 78ms/step - accuracy: 0.4589 - loss: 1.5624 - val_accuracy: 0.6070 - val_loss: 0.9738\n",
            "Epoch 2/10\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 69ms/step - accuracy: 0.5899 - loss: 0.9682 - val_accuracy: 0.6520 - val_loss: 0.8607\n",
            "Epoch 3/10\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 74ms/step - accuracy: 0.6446 - loss: 0.8622 - val_accuracy: 0.6915 - val_loss: 0.7924\n",
            "Epoch 4/10\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 74ms/step - accuracy: 0.6869 - loss: 0.7571 - val_accuracy: 0.7295 - val_loss: 0.6344\n",
            "Epoch 5/10\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 73ms/step - accuracy: 0.7141 - loss: 0.6978 - val_accuracy: 0.7380 - val_loss: 0.6896\n",
            "Epoch 6/10\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 70ms/step - accuracy: 0.7480 - loss: 0.6273 - val_accuracy: 0.7330 - val_loss: 0.7519\n",
            "Epoch 7/10\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 69ms/step - accuracy: 0.7630 - loss: 0.5869 - val_accuracy: 0.7745 - val_loss: 0.5796\n",
            "Epoch 8/10\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 70ms/step - accuracy: 0.7888 - loss: 0.5328 - val_accuracy: 0.8055 - val_loss: 0.5247\n",
            "Epoch 9/10\n",
            "\u001b[1m719/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.8154 - loss: 0.4667"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9f0I-9prZGTu"
      },
      "outputs": [],
      "source": [
        "for layer in model.layers[-50:]:\n",
        "    layer.trainable = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cd-UDOZcQzxD"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "# Model Checkpoint - save only the best model\n",
        "checkpoint_cb = ModelCheckpoint(\n",
        "    \"model_InceptionV3.keras\",  # Updated filename\n",
        "    save_best_only=True\n",
        ")\n",
        "\n",
        "# Early Stopping - stop if no improvement for 10 epochs\n",
        "early_stopping_cb = EarlyStopping(\n",
        "    patience=10,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(1e-4),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gWSAdkheQzxE"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 25"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0B5UpPXlQzxF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31916b82-6425-4908-ac89-05c6eb0521df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m259s\u001b[0m 249ms/step - accuracy: 0.5912 - loss: 1.4650 - val_accuracy: 0.7260 - val_loss: 0.7373\n",
            "Epoch 2/25\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 249ms/step - accuracy: 0.8363 - loss: 0.4153 - val_accuracy: 0.8825 - val_loss: 0.2963\n",
            "Epoch 3/25\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 236ms/step - accuracy: 0.9264 - loss: 0.1887 - val_accuracy: 0.8925 - val_loss: 0.3042\n",
            "Epoch 4/25\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 243ms/step - accuracy: 0.9528 - loss: 0.1301 - val_accuracy: 0.9005 - val_loss: 0.2845\n",
            "Epoch 5/25\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 245ms/step - accuracy: 0.9628 - loss: 0.1075 - val_accuracy: 0.9435 - val_loss: 0.1726\n",
            "Epoch 6/25\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 236ms/step - accuracy: 0.9653 - loss: 0.1014 - val_accuracy: 0.9295 - val_loss: 0.1991\n",
            "Epoch 7/25\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 240ms/step - accuracy: 0.9735 - loss: 0.0742 - val_accuracy: 0.9090 - val_loss: 0.2855\n",
            "Epoch 8/25\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 248ms/step - accuracy: 0.9790 - loss: 0.0645 - val_accuracy: 0.9555 - val_loss: 0.1252\n",
            "Epoch 9/25\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 237ms/step - accuracy: 0.9803 - loss: 0.0611 - val_accuracy: 0.9540 - val_loss: 0.1301\n",
            "Epoch 10/25\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 245ms/step - accuracy: 0.9769 - loss: 0.0648 - val_accuracy: 0.9780 - val_loss: 0.0695\n",
            "Epoch 11/25\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 241ms/step - accuracy: 0.9865 - loss: 0.0406 - val_accuracy: 0.8905 - val_loss: 0.3091\n",
            "Epoch 12/25\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 237ms/step - accuracy: 0.9886 - loss: 0.0349 - val_accuracy: 0.8810 - val_loss: 0.3735\n",
            "Epoch 13/25\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 241ms/step - accuracy: 0.9755 - loss: 0.0677 - val_accuracy: 0.9765 - val_loss: 0.0597\n",
            "Epoch 14/25\n",
            "\u001b[1m 92/750\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:29\u001b[0m 227ms/step - accuracy: 0.9942 - loss: 0.0203"
          ]
        }
      ],
      "source": [
        "# Now train with class weights\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=val_ds,\n",
        "    callbacks=[checkpoint_cb, early_stopping_cb],\n",
        "    # class_weight=class_weights\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n5SuJk5_UZrI"
      },
      "outputs": [],
      "source": [
        "model.save(\"/content/drive/MyDrive/AI/inception_model.h5\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yUh4ktTVQzxH"
      },
      "outputs": [],
      "source": [
        "model.save('/content/model_InceptionV3.keras')\n",
        "model.export('/content/models/inceptionV3_model')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MXOspV2RQzxO"
      },
      "outputs": [],
      "source": [
        "hist_=pd.DataFrame(history.history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z2oziusVQzxM"
      },
      "outputs": [],
      "source": [
        "score, acc= model.evaluate(test_ds)\n",
        "print('Val Loss =', score)\n",
        "print('Val Accuracy =', acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sOTXUrMxQzxQ"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(15,10))\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(hist_['loss'],label='Train_Loss')\n",
        "plt.plot(hist_['val_loss'],label='Validation_Loss')\n",
        "plt.title('Train_Loss & Validation_Loss',fontsize=20)\n",
        "plt.legend()\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(hist_['accuracy'],label='Train_Accuracy')\n",
        "plt.plot(hist_['val_accuracy'],label='Validation_Accuracy')\n",
        "plt.title('Train_Accuracy & Validation_Accuracy',fontsize=20)\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tYvMVpvJQzxS"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Convert test labels (one-hot) to class indices\n",
        "y_test_labels = []\n",
        "for batch in test_ds:\n",
        "    images, labels = batch\n",
        "    y_test_labels.append(labels.numpy())\n",
        "\n",
        "y_test = np.concatenate(y_test_labels, axis=0)\n",
        "y_test = np.argmax(y_test, axis=1)  # Convert one-hot to class index\n",
        "\n",
        "# Predict using model\n",
        "predictions = model.predict(test_ds)\n",
        "y_pred = np.argmax(predictions, axis=1)  # Class index\n",
        "\n",
        "# Create a DataFrame with Actual vs Prediction\n",
        "df = pd.DataFrame({'Actual': y_test, 'Prediction': y_pred})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n6S-hs0DQzxU"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Ensure your predicted and true labels are available\n",
        "# y_test and y_pred should be 1D arrays of class indices\n",
        "\n",
        "# Define class labels (update to match your actual class names)\n",
        "class_names = ['MildDemented', 'ModerateDemented', 'NonDemented', 'VeryMildDemented']\n",
        "\n",
        "# Compute the confusion matrix\n",
        "CM = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Normalize the confusion matrix\n",
        "CM_percent = CM.astype('float') / CM.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "# Plot the heatmap\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(CM_percent,\n",
        "            fmt='.2f',\n",
        "            annot=True,\n",
        "            cmap='Blues',\n",
        "            xticklabels=class_names,\n",
        "            yticklabels=class_names,\n",
        "            cbar=False)\n",
        "\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Normalized Confusion Matrix')\n",
        "plt.show()\n",
        "\n",
        "# Optionally print the raw CM\n",
        "CM\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZY7brHMYQzxW"
      },
      "outputs": [],
      "source": [
        "ClassificationReport = classification_report(y_test,y_pred,target_names=class_names)\n",
        "print('Classification Report is : ', ClassificationReport)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}