{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNiwdvqPeE4IJ16skUHw0D+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LikaOkudzhava/BrainyScan/blob/main/KerasTuner.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aNs8dKGXTUms",
        "outputId": "497966df-143e-4108-edc1-c0cbffbd81dc"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "from google.colab import drive\n",
        "gdrive = '/content/drive'\n",
        "drive.mount(gdrive, force_remount=False)\n",
        "gdisk = os.path.join(gdrive, 'MyDrive')\n",
        "filename = 'smallpreprocessed'\n",
        "archive_path = os.path.join(gdisk, filename)\n",
        "with zipfile.ZipFile('/content/drive/MyDrive/smallpreprocessed.zip', 'r') as zip_ref:\n",
        " zip_ref.extractall(f'{filename}_extracted')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rusMMEMhTUSI",
        "outputId": "af85d983-8d32-4f91-a57f-ab55dfc4fe19"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras_tuner"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FUQzShqbbuav",
        "outputId": "5f6d1d97-98f1-47ba-8901-a3b0b7c2c461"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras_tuner\n",
            "  Downloading keras_tuner-1.4.7-py3-none-any.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.11/dist-packages (from keras_tuner) (3.8.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from keras_tuner) (24.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from keras_tuner) (2.32.3)\n",
            "Collecting kt-legacy (from keras_tuner)\n",
            "  Downloading kt_legacy-1.0.5-py3-none-any.whl.metadata (221 bytes)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from keras->keras_tuner) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from keras->keras_tuner) (2.0.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras->keras_tuner) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras->keras_tuner) (0.0.9)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from keras->keras_tuner) (3.13.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras->keras_tuner) (0.15.0)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.11/dist-packages (from keras->keras_tuner) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->keras_tuner) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->keras_tuner) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->keras_tuner) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->keras_tuner) (2025.4.26)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from optree->keras->keras_tuner) (4.13.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras->keras_tuner) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras->keras_tuner) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras->keras_tuner) (0.1.2)\n",
            "Downloading keras_tuner-1.4.7-py3-none-any.whl (129 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.1/129.1 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
            "Installing collected packages: kt-legacy, keras_tuner\n",
            "Successfully installed keras_tuner-1.4.7 kt-legacy-1.0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "import cv2\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "import keras\n",
        "from keras.callbacks import EarlyStopping,ModelCheckpoint\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "from keras.callbacks import EarlyStopping,ReduceLROnPlateau,ModelCheckpoint,TensorBoard,LambdaCallback\n",
        "from keras.layers import Input,Dropout, Dense,GlobalAveragePooling2D, BatchNormalization\n",
        "from keras.models import Sequential,Model\n",
        "from keras.applications.resnet import ResNet50\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix,classification_report\n",
        "from sklearn.utils import shuffle\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "from tqdm import tqdm\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import itertools\n",
        "import datetime\n",
        "import keras_tuner as kt\n"
      ],
      "metadata": {
        "id": "vEuWNkC4TnKG"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_dir = '/content/smallpreprocessed_extracted/data/SmallPreprocessed'\n",
        "image_size = (224, 224)\n",
        "batch_size = 32\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    preprocessing_function= tf.keras.applications.resnet.preprocess_input,\n",
        "    rescale=1./255,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "train_generator = datagen.flow_from_directory(\n",
        "    os.path.join(dataset_dir, 'train'),\n",
        "    target_size = image_size,\n",
        "    batch_size = batch_size,\n",
        "    class_mode = 'categorical',\n",
        "    shuffle = True\n",
        ")\n",
        "\n",
        "test_generator = datagen.flow_from_directory(\n",
        "    os.path.join(dataset_dir, 'test'),\n",
        "    target_size = image_size,\n",
        "    batch_size = batch_size,\n",
        "    class_mode = 'categorical',\n",
        "    shuffle = False\n",
        ")\n",
        "\n",
        "val_generator = datagen.flow_from_directory(\n",
        "    os.path.join(dataset_dir, 'val'),\n",
        "    target_size = image_size,\n",
        "    batch_size = batch_size,\n",
        "    class_mode = 'categorical',\n",
        "    shuffle = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_1yPlg9ZTqCw",
        "outputId": "ef2e9bcc-d14c-4c29-fef9-5020860891b5"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 12000 images belonging to 4 classes.\n",
            "Found 2000 images belonging to 4 classes.\n",
            "Found 2000 images belonging to 4 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "8OiPBtDzTRtZ"
      },
      "outputs": [],
      "source": [
        "def build_model(hp):\n",
        "    model = Sequential()\n",
        "\n",
        "    # Add the pre-trained ResNet50 base\n",
        "    # freezing it initially, as it's the standard for transfer learning base\n",
        "    # pooling='avg' handles the global average pooling\n",
        "    resnet_base = ResNet50(\n",
        "        input_shape=(image_size[0], image_size[1], 3),\n",
        "        include_top=False,\n",
        "        pooling='avg',\n",
        "        weights='imagenet'\n",
        "    )\n",
        "    resnet_base.trainable = False # Freeze the base model\n",
        "    model.add(resnet_base)\n",
        "\n",
        "    # first dense layer\n",
        "    hp_dense1 = hp.Choice(\n",
        "        'dense1', # Name of the hyperparameter\n",
        "        values=[512, 1024, 2048] # The values to try for the first dense layer\n",
        "    )\n",
        "    model.add(Dense(units=hp_dense1, activation='relu'))\n",
        "    model.add(BatchNormalization()) # Keep BatchNormalization ?\n",
        "\n",
        "   # second dense layer\n",
        "    hp_dense2 = hp.Choice(\n",
        "        'dense2',\n",
        "        values=[256, 512, 1024] # The values to try for the second dense layer\n",
        "    )\n",
        "    model.add(Dense(units=hp_dense2, activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    # dropout rates\n",
        "    hp_dropout_rate = hp.Choice(\n",
        "        'dropout_rate',\n",
        "        values=[0.2, 0.3, 0.4, 0.5]\n",
        "    )\n",
        "    model.add(Dropout(hp_dropout_rate))\n",
        "\n",
        "\n",
        "    # Final output layer\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "   # learning rate\n",
        "    hp_learning_rate = hp.Choice(\n",
        "        'learning_rate',\n",
        "        values=[0.0001, 0.00005, 0.00001]\n",
        "    )\n",
        "\n",
        "    optimizer = keras.optimizers.Adam(learning_rate=hp_learning_rate)\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate the KerasTuner\n",
        "\n",
        "\n",
        "num_classes = train_generator.num_classes\n",
        "\n",
        "tuner = kt.RandomSearch(\n",
        "    build_model,\n",
        "    objective='val_accuracy',\n",
        "    max_trials=20, # try 20 different combinations of hyperparameters\n",
        "    executions_per_trial=1, # each trial trains the model once\n",
        "    directory='keras_tuner_dir', # Folder to save tuning results\n",
        "    project_name='mri_resnet_tuning'\n",
        ")\n",
        "\n",
        "# Print a summary of the search space\n",
        "tuner.search_space_summary()\n",
        "\n",
        "\n",
        "print(\"\\nStarting hyperparameter search...\\n\")\n",
        "tuner.search(\n",
        "    train_generator,\n",
        "    epochs=20,\n",
        "    validation_data=val_generator,\n",
        "    callbacks=[\n",
        "        keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
        "        keras.callbacks.ModelCheckpoint(\"tuned_model_temp.keras\", save_best_only=True, monitor='val_accuracy', mode='max')\n",
        "\n",
        "    ]\n",
        ")\n",
        "\n",
        "# --- 4. Get the best model and print results ---\n",
        "print(\"\\nHyperparameter search complete.\\n\")\n",
        "tuner.results_summary()\n",
        "\n",
        "# Get the best model(s)\n",
        "best_models = tuner.get_best_models(num_models=1)\n",
        "best_model = best_models[0]\n",
        "\n",
        "print(\"\\nBest model summary:\")\n",
        "best_model.summary()\n",
        "\n",
        "print(\"\\nEvaluating the best model on test data:\")\n",
        "loss, accuracy = best_model.evaluate(test_generator)\n",
        "print(f\"Test Loss: {loss:.4f}\")\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# You can save the final best model\n",
        "best_model.save(\"best_mri_resnet_model.keras\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QgdvZz8OXgHN",
        "outputId": "48f78b93-47b8-4a68-ef0e-d20619238715"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Search space summary\n",
            "Default search space size: 4\n",
            "dense1 (Choice)\n",
            "{'default': 512, 'conditions': [], 'values': [512, 1024, 2048], 'ordered': True}\n",
            "dense2 (Choice)\n",
            "{'default': 256, 'conditions': [], 'values': [256, 512, 1024], 'ordered': True}\n",
            "dropout_rate (Choice)\n",
            "{'default': 0.2, 'conditions': [], 'values': [0.2, 0.3, 0.4, 0.5], 'ordered': True}\n",
            "learning_rate (Choice)\n",
            "{'default': 0.0001, 'conditions': [], 'values': [0.0001, 5e-05, 1e-05], 'ordered': True}\n",
            "\n",
            "Starting hyperparameter search...\n",
            "\n",
            "\n",
            "Search: Running Trial #1\n",
            "\n",
            "Value             |Best Value So Far |Hyperparameter\n",
            "2048              |2048              |dense1\n",
            "1024              |1024              |dense2\n",
            "0.5               |0.5               |dropout_rate\n",
            "5e-05             |5e-05             |learning_rate\n",
            "\n",
            "Epoch 1/20\n",
            "\u001b[1m242/375\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m13:17\u001b[0m 6s/step - accuracy: 0.4010 - loss: 1.6858"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "A5RuLj5NfkHJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}