{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "btBqZ8acSkbL"
      },
      "outputs": [],
      "source": [
        "\n",
        "import os, shutil\n",
        "import cv2\n",
        "import zipfile\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "import keras\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def zipdir(src_path: str, zip_file: zipfile.ZipFile):\n",
        "    ''' add dirctory with relative path to the zip archive\n",
        "\n",
        "    Args:\n",
        "      src_path: path to the directory\n",
        "      zip_file: zip archive\n",
        "    '''\n",
        "    for root, dirs, files in os.walk(src_path):\n",
        "        for file in files:\n",
        "            file_path = os.path.join(root, file)\n",
        "            # Добавляем файл в архив с относительным путем\n",
        "            arcname = os.path.relpath(file_path, src_path)\n",
        "            zip_file.write(file_path, arcname)\n"
      ],
      "metadata": {
        "id": "mh1u7Zuhx2zi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hvd19qv9Sp1r",
        "outputId": "d5eb3dd9-eaa1-45c0-a3e0-4b4ba876f445"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "filename = 'smallpreprocessed.zip'\n",
        "\n",
        "dest_path = f'{filename}_extracted'\n",
        "shutil.rmtree(dest_path, ignore_errors=True)\n",
        "\n",
        "with zipfile.ZipFile( os.path.join('/content/drive/MyDrive', filename), 'r') as zip_ref:\n",
        "    zip_ref.extractall(dest_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X7gix72mSkbN"
      },
      "outputs": [],
      "source": [
        "dataset_dir = os.path.join('/content/', dest_path, 'data', 'SmallPreprocessed')\n",
        "image_size = (224, 224)\n",
        "batch_size = 32\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    preprocessing_function= tf.keras.applications.resnet.preprocess_input,\n",
        "    rescale=1./255\n",
        ")\n",
        "\n",
        "train_generator = datagen.flow_from_directory(\n",
        "    os.path.join(dataset_dir, 'train'),\n",
        "    target_size = image_size,\n",
        "    batch_size = batch_size,\n",
        "    class_mode = 'categorical',\n",
        "    shuffle = True\n",
        ")\n",
        "\n",
        "test_generator = datagen.flow_from_directory(\n",
        "    os.path.join(dataset_dir, 'test'),\n",
        "    target_size = image_size,\n",
        "    batch_size = batch_size,\n",
        "    class_mode = 'categorical',\n",
        "    shuffle = False\n",
        ")\n",
        "\n",
        "val_generator = datagen.flow_from_directory(\n",
        "    os.path.join(dataset_dir, 'val'),\n",
        "    target_size = image_size,\n",
        "    batch_size = batch_size,\n",
        "    class_mode = 'categorical',\n",
        "    shuffle = True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cVv6dGXEbNQ1"
      },
      "outputs": [],
      "source": [
        "class_num = list(train_generator.class_indices.keys())\n",
        "class_num"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a1Y2MdwmsJyS"
      },
      "outputs": [],
      "source": [
        "SEED = 42"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aahW7b7WSkbO"
      },
      "outputs": [],
      "source": [
        "model = keras.models.Sequential()\n",
        "\n",
        "model.add(Conv2D(32, (4, 4), activation=\"relu\", input_shape=(image_size[0], image_size[1], 3)))\n",
        "model.add(MaxPooling2D(pool_size=(3, 3)))\n",
        "\n",
        "model.add(Conv2D(64, (4, 4), activation=\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=(3, 3)))\n",
        "\n",
        "model.add(Conv2D(128, (4, 4), activation=\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=(3, 3)))\n",
        "\n",
        "model.add(Conv2D(128, (4, 4), activation=\"relu\"))\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(512, activation=\"relu\"))\n",
        "model.add(Dropout(0.5, seed=SEED))\n",
        "\n",
        "model.add(Dense(len(class_num), activation=\"softmax\"))\n",
        "\n",
        "# Build the model with the correct input shape\n",
        "# model.build(input_shape=(None, image_size[0], image_size[1], 3))\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RbZPk4VHSkbP"
      },
      "outputs": [],
      "source": [
        "checkpoint_cb = ModelCheckpoint(\n",
        "    \"model_VGG16.keras\",\n",
        "    save_best_only = True)\n",
        "\n",
        "early_stopping_cb = EarlyStopping(\n",
        "    patience = 10,\n",
        "    restore_best_weights = True\n",
        ")\n",
        "\n",
        "model.compile(\n",
        "    optimizer = 'adam',\n",
        "    loss = 'categorical_crossentropy',\n",
        "    metrics = ['accuracy']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DPYH33cwSkbP"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ua6nmoGZSkbQ"
      },
      "outputs": [],
      "source": [
        "hist = model.fit(\n",
        "    train_generator,\n",
        "    epochs = EPOCHS,\n",
        "    validation_data = val_generator,\n",
        "    callbacks = [checkpoint_cb, early_stopping_cb]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VEppHSJrSkbQ"
      },
      "outputs": [],
      "source": [
        "model.save('models/handmade_model.keras')\n",
        "model.export('models/handmade_model')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VW6n-MNhSkbQ"
      },
      "outputs": [],
      "source": [
        "score, acc= model.evaluate(test_generator)\n",
        "print('Val Loss =', score)\n",
        "print('Val Accuracy =', acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "obrmiVZ1SkbR"
      },
      "outputs": [],
      "source": [
        "hist_=pd.DataFrame(hist.history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8gW_1Y1vSkbR"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(15,10))\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(hist_['loss'],label='Train_Loss')\n",
        "plt.plot(hist_['val_loss'],label='Validation_Loss')\n",
        "plt.title('Train_Loss & Validation_Loss',fontsize=20)\n",
        "plt.legend()\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(hist_['accuracy'],label='Train_Accuracy')\n",
        "plt.plot(hist_['val_accuracy'],label='Validation_Accuracy')\n",
        "plt.title('Train_Accuracy & Validation_Accuracy',fontsize=20)\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "owOWWWH7SkbS"
      },
      "outputs": [],
      "source": [
        "y_test =test_generator.classes\n",
        "predictions = model.predict(test_generator)\n",
        "y_pred = np.argmax(predictions,axis=1)\n",
        "y_test = np.ravel(y_test)\n",
        "y_pred = np.ravel(y_pred)\n",
        "df = pd.DataFrame({'Actual': y_test, 'Prediction': y_pred})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wE9klsjdSkbS"
      },
      "outputs": [],
      "source": [
        "CM = confusion_matrix(y_test,y_pred)\n",
        "CM_percent = CM.astype('float') / CM.sum(axis=1)[:, np.newaxis]\n",
        "sns.heatmap(CM_percent,fmt='g',center = True,cbar=False,annot=True,cmap='Blues',xticklabels=class_num, yticklabels=class_num)\n",
        "CM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MyaolJ4GSkbS"
      },
      "outputs": [],
      "source": [
        "ClassificationReport = classification_report(y_test,y_pred,target_names=class_num)\n",
        "print('Classification Report is : ', ClassificationReport)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}